{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/01 20:13:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/01 20:13:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create the Spark session\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ADBFinacialReportsSecDataPreparation\")\\\n",
    "        .config(\"spark.sql.shuffle.partitions\",200)\\\n",
    "        .config(\"spark.driver.memory\", \"16G\")\\\n",
    "        .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Datasets/financial-reports-sec/data/large/\"\n",
    "output_dir = \"../Datasets/financial-reports-sec/parquet/large/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_sections(col_list):\n",
    "  # Concatenate elements in each array into a single string for each section\n",
    "  concat_array_cols = [F.concat_ws(\" \", F.col(section)).alias(section) for section in col_list]\n",
    "  \n",
    "  return F.concat_ws(\" \", *concat_array_cols).alias(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_transform(df):\n",
    "  # List of sections to concatenate\n",
    "  sections = [\n",
    "    \"filing.report.section_1\", \"filing.report.section_1A\", \"filing.report.section_1B\",\n",
    "    \"filing.report.section_2\", \"filing.report.section_3\", \"filing.report.section_4\",\n",
    "    \"filing.report.section_5\", \"filing.report.section_6\", \"filing.report.section_7\",\n",
    "    \"filing.report.section_7A\", \"filing.report.section_8\", \"filing.report.section_9\",\n",
    "    \"filing.report.section_9A\", \"filing.report.section_9B\", \"filing.report.section_10\",\n",
    "    \"filing.report.section_11\", \"filing.report.section_12\", \"filing.report.section_13\",\n",
    "    \"filing.report.section_14\", \"filing.report.section_15\"\n",
    "  ]\n",
    "  # Explode the filings array to get one row per filing\n",
    "  df_exploded = df.withColumn(\"filing\", F.explode(\"filings\")).drop(\"filings\")\n",
    "\n",
    "  # Concatenate all sections into one single text field\n",
    "  df_exploded = df_exploded.withColumn(\"report\", concat_sections(sections))\n",
    "\n",
    "  # Extract labels, dates and returns fields\n",
    "  df_exploded = df_exploded \\\n",
    "  .withColumn(\"labels_1d\", F.col(\"filing.labels.1d\")) \\\n",
    "  .withColumn(\"labels_30d\", F.col(\"filing.labels.30d\")) \\\n",
    "  .withColumn(\"labels_5d\", F.col(\"filing.labels.5d\")) \\\n",
    "  .withColumn(\"returns_1d_closePriceEndDate\", F.col(\"filing.returns.1d.closePriceEndDate\")) \\\n",
    "  .withColumn(\"returns_1d_closePriceStartDate\", F.col(\"filing.returns.1d.closePriceStartDate\")) \\\n",
    "  .withColumn(\"returns_1d_endDate\", F.col(\"filing.returns.1d.endDate\")) \\\n",
    "  .withColumn(\"returns_1d_ret\", F.col(\"filing.returns.1d.ret\")) \\\n",
    "  .withColumn(\"returns_1d_startDate\", F.col(\"filing.returns.1d.startDate\")) \\\n",
    "  .withColumn(\"returns_30d_closePriceEndDate\", F.col(\"filing.returns.30d.closePriceEndDate\")) \\\n",
    "  .withColumn(\"returns_30d_closePriceStartDate\", F.col(\"filing.returns.30d.closePriceStartDate\")) \\\n",
    "  .withColumn(\"returns_30d_endDate\", F.col(\"filing.returns.30d.endDate\")) \\\n",
    "  .withColumn(\"returns_30d_ret\", F.col(\"filing.returns.30d.ret\")) \\\n",
    "  .withColumn(\"returns_30d_startDate\", F.col(\"filing.returns.30d.startDate\")) \\\n",
    "  .withColumn(\"returns_5d_closePriceEndDate\", F.col(\"filing.returns.5d.closePriceEndDate\")) \\\n",
    "  .withColumn(\"returns_5d_closePriceStartDate\", F.col(\"filing.returns.5d.closePriceStartDate\")) \\\n",
    "  .withColumn(\"returns_5d_endDate\", F.col(\"filing.returns.5d.endDate\")) \\\n",
    "  .withColumn(\"returns_5d_ret\", F.col(\"filing.returns.5d.ret\")) \\\n",
    "  .withColumn(\"returns_5d_startDate\", F.col(\"filing.returns.5d.startDate\")) \\\n",
    "  .withColumn(\"acceptanceDateTime\", F.col(\"filing.acceptanceDateTime\")) \\\n",
    "  .withColumn(\"filingDate\", F.col(\"filing.filingDate\")) \\\n",
    "  .withColumn(\"reportDate\", F.col(\"filing.reportDate\")) \\\n",
    "  .withColumn(\"form\", F.col(\"filing.form\")) \\\n",
    "  .drop(\"filing\")\n",
    "\n",
    "  df_exploded = df_exploded \\\n",
    "  .withColumn(\"labels_1d_num\", F.when(F.col(\"labels_1d\") == \"positive\", \"1\").otherwise(\"0\")) \\\n",
    "  .withColumn(\"labels_5d_num\", F.when(F.col(\"labels_5d\") == \"positive\", \"1\").otherwise(\"0\")) \\\n",
    "  .withColumn(\"labels_30d_num\", F.when(F.col(\"labels_30d\") == \"positive\", \"1\").otherwise(\"0\")) \\\n",
    "  .withColumn(\"labels_concat\", F.concat(\"labels_30d_num\", \"labels_5d_num\", \"labels_1d_num\")) \\\n",
    "  .withColumn(\"label\", F.udf(lambda x: int(x, 2), IntegerType())(\"labels_concat\"))\n",
    "\n",
    "  return df_exploded.select([\"name\", \"label\", \"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Original Size: 468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Original Size: 3741\n",
      "Validate Original Size: 468\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read.json(data_dir + \"test\")\n",
    "print(\"Test Original Size: \" + str(df_test.count()))\n",
    "\n",
    "df_train = spark.read.json(data_dir + \"train\")\n",
    "print(\"Train Original Size: \" + str(df_train.count()))\n",
    "\n",
    "df_validate = spark.read.json(data_dir + \"validate\")\n",
    "print(\"Validate Original Size: \" + str(df_validate.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cik: string (nullable = true)\n",
      " |-- entityType: string (nullable = true)\n",
      " |-- exchanges: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filings: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- acceptanceDateTime: string (nullable = true)\n",
      " |    |    |-- filingDate: string (nullable = true)\n",
      " |    |    |-- form: string (nullable = true)\n",
      " |    |    |-- labels: struct (nullable = true)\n",
      " |    |    |    |-- 1d: string (nullable = true)\n",
      " |    |    |    |-- 30d: string (nullable = true)\n",
      " |    |    |    |-- 5d: string (nullable = true)\n",
      " |    |    |-- report: struct (nullable = true)\n",
      " |    |    |    |-- section_1: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_10: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_11: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_12: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_13: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_14: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_15: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_1A: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_1B: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_2: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_3: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_4: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_5: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_6: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_7: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_7A: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_8: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_9: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_9A: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- section_9B: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- reportDate: string (nullable = true)\n",
      " |    |    |-- returns: struct (nullable = true)\n",
      " |    |    |    |-- 1d: struct (nullable = true)\n",
      " |    |    |    |    |-- closePriceEndDate: double (nullable = true)\n",
      " |    |    |    |    |-- closePriceStartDate: double (nullable = true)\n",
      " |    |    |    |    |-- endDate: string (nullable = true)\n",
      " |    |    |    |    |-- ret: double (nullable = true)\n",
      " |    |    |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |    |-- 30d: struct (nullable = true)\n",
      " |    |    |    |    |-- closePriceEndDate: double (nullable = true)\n",
      " |    |    |    |    |-- closePriceStartDate: double (nullable = true)\n",
      " |    |    |    |    |-- endDate: string (nullable = true)\n",
      " |    |    |    |    |-- ret: double (nullable = true)\n",
      " |    |    |    |    |-- startDate: string (nullable = true)\n",
      " |    |    |    |-- 5d: struct (nullable = true)\n",
      " |    |    |    |    |-- closePriceEndDate: double (nullable = true)\n",
      " |    |    |    |    |-- closePriceStartDate: double (nullable = true)\n",
      " |    |    |    |    |-- endDate: string (nullable = true)\n",
      " |    |    |    |    |-- ret: double (nullable = true)\n",
      " |    |    |    |    |-- startDate: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sic: string (nullable = true)\n",
      " |-- stateOfIncorporation: string (nullable = true)\n",
      " |-- tickerCount: long (nullable = true)\n",
      " |-- tickers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Transformed Size: 1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Transformed Size: 52663\n",
      "Validate Transformed Size: 866\n"
     ]
    }
   ],
   "source": [
    "df_test = df_transform(df_test)\n",
    "print(\"Test Transformed Size: \" + str(df_test.count()))\n",
    "\n",
    "df_train = df_transform(df_train)\n",
    "print(\"Train Transformed Size: \" + str(df_train.count()))\n",
    "\n",
    "df_validate = df_transform(df_validate)\n",
    "print(\"Validate Transformed Size: \" + str(df_validate.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- report: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:============================================>        (100 + 13) / 118]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Dataset Size: 55349\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- report: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_full = df_test.union(df_train).union(df_validate)\n",
    "print(\"Complete Dataset Size: \" + str(df_full.count()))\n",
    "df_full.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test, df_train, df_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df_full.sampleBy(\n",
    "  \"label\", \n",
    "  fractions={\n",
    "    0: 0.5,\n",
    "    1: 0.5,\n",
    "    2: 0.5,\n",
    "    3: 0.5,\n",
    "    4: 0.5,\n",
    "    5: 0.5,\n",
    "    6: 0.5,\n",
    "    7: 0.5,\n",
    "    8: 0.5\n",
    "  },\n",
    "  seed = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_full.write.mode(\"overwrite\").parquet(output_dir + \"full.parquet\")\n",
    "\n",
    "del df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_small.sampleBy(\n",
    "  \"label\", \n",
    "  fractions={\n",
    "    0: 0.8,\n",
    "    1: 0.8,\n",
    "    2: 0.8,\n",
    "    3: 0.8,\n",
    "    4: 0.8,\n",
    "    5: 0.8,\n",
    "    6: 0.8,\n",
    "    7: 0.8,\n",
    "    8: 0.8\n",
    "  },\n",
    "  seed = 7\n",
    ")\n",
    "\n",
    "df_test = df_small.subtract(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 8159|\n",
      "|    7| 6820|\n",
      "|    4| 3740|\n",
      "|    3| 2603|\n",
      "|    6| 2163|\n",
      "|    1| 1755|\n",
      "|    5| 1250|\n",
      "|    2| 1220|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 6448|\n",
      "|    7| 5454|\n",
      "|    4| 2956|\n",
      "|    3| 2084|\n",
      "|    6| 1723|\n",
      "|    1| 1395|\n",
      "|    5|  996|\n",
      "|    2|  951|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                       (0 + 12) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1709|\n",
      "|    7| 1364|\n",
      "|    4|  780|\n",
      "|    3|  518|\n",
      "|    6|  439|\n",
      "|    1|  360|\n",
      "|    2|  267|\n",
      "|    5|  253|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_small.groupBy(\"label\").count().orderBy(F.col(\"count\").desc()).show()\n",
    "df_train.groupBy(\"label\").count().orderBy(F.col(\"count\").desc()).show()\n",
    "df_test.groupBy(\"label\").count().orderBy(F.col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_small.write.mode(\"overwrite\").parquet(output_dir + \"small.parquet\")\n",
    "df_train.write.mode(\"overwrite\").parquet(output_dir + \"train.parquet\")\n",
    "df_test.write.mode(\"overwrite\").parquet(output_dir + \"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
